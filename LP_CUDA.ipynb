{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import networkx as nx\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import LP\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "class LocalSimilarity():\n",
    "    def __init__(self, names, path_to_save, func, model):\n",
    "        for n in names:\n",
    "            G = nx.read_gml(f'CUDA_dataset/GMLs/{n}.gml')\n",
    "            \n",
    "            _ = self.LP_exmperiment1(G,n, func)            \n",
    "\n",
    "    def LP_exmperiment1(self, G, n, func):\n",
    "        Nodes = list(G.nodes())\n",
    "        print(f'')\n",
    "\n",
    "        E = list(G.edges())\n",
    "        \n",
    "        # Split the edges into train and validation sets\n",
    "        train_data, val_data = train_test_split(E, test_size=0.2)  # Adjust test_size as needed\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        gT, gP = nx.Graph(), nx.Graph()\n",
    "        gT.add_nodes_from(Nodes)\n",
    "        gP.add_nodes_from(Nodes)\n",
    "\n",
    "        gT.add_edges_from(train_data)\n",
    "        gP.add_edges_from(val_data)\n",
    "\n",
    "        S = []\n",
    "        for u in gT.nodes():\n",
    "            for v in gT.nodes():\n",
    "                if not gT.has_edge(u, v):\n",
    "                    Nv, Nu = list(gT.neighbors(v)), list(gT.neighbors(u))\n",
    "                    Sxy = func(gT, v, u, Nv, Nu)\n",
    "                    y = 1 if gP.has_edge(v, u) else 0\n",
    "\n",
    "                    S.append([Sxy, y])\n",
    "\n",
    "        end_time = time.time() - start_time\n",
    "        res, y = zip(*S)\n",
    "        print(f'{n},Nodes,{len(Nodes)},Edges,{len(G.edges)},time,{end_time},AUC,{LP.get_AUC(y, res)}')\n",
    "    \n",
    "    \n",
    "    def LP_exmperiment(self, G, n, func):\n",
    "        Nodes = list(G.nodes())\n",
    "        # U = nx.Graph()\n",
    "        # U.add_nodes_from(Nodes)\n",
    "        # U.add_edges_from(LP.getU(list(G.nodes())))\n",
    "        # eU = list(U.edges())\n",
    "        print(f'Nodes = {len(Nodes)}\\nEdges = {len(G.edges)}')\n",
    "        # ------------------------------------------------\n",
    "        S = []\n",
    "        \n",
    "        kfold = KFold(n_splits=5, shuffle=True)\n",
    "        E = list(G.edges())\n",
    "        i = 1\n",
    "        for train_index, val_index in kfold.split(E)[0]:\n",
    "            start_time = time.time()\n",
    "            train_data = [E[i] for i in train_index]\n",
    "            val_data   = [E[i] for i in val_index]\n",
    "\n",
    "            # print(len(train_data), len(val_data))\n",
    "\n",
    "            # exit(1)\n",
    "            gT, gP = nx.Graph(), nx.Graph()\n",
    "                \n",
    "            gT.add_nodes_from(Nodes)\n",
    "            gP.add_nodes_from(Nodes)\n",
    "            \n",
    "            gT.add_edges_from(train_data)\n",
    "            gP.add_edges_from(val_data)\n",
    "\n",
    "            # ------------------------------------------------\n",
    "            # for v,u in L:\n",
    "            for u in gT.nodes():\n",
    "                for v in gT.nodes():\n",
    "                    if not gT.has_edge(u,v):\n",
    "                        Nv, Nu  = list(gT.neighbors(v)), list(gT.neighbors(u))\n",
    "                        Sxy = func(gT, v, u, Nv, Nu)\n",
    "                        y = 1 if gP.has_edge(v,u) else 0\n",
    "\n",
    "                        S.append([Sxy, y])\n",
    "\n",
    "            end_time = time.time() - start_time\n",
    "            res, y = zip(*S)\n",
    "            print(f'time consumed is: {end_time} seconds...AUC = {LP.get_AUC(y, res)}')\n",
    "\n",
    "            # print(f'{n} \\t iteration number :{i}\\t{len(train_data)}\\t{len(val_data)}\\t{len(L)}')\n",
    "            i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_graph(filePath):\n",
    "    G = nx.Graph()\n",
    "    with open(filePath, 'r') as file:\n",
    "        next(file)  # Skip the header line (if there is one)\n",
    "        for line in file:\n",
    "            node1, node2 = line.strip().split(',')\n",
    "            G.add_edge(int(node1), int(node2))\n",
    "    return G\n",
    "\n",
    "def convert_graph(G, edges_file_path):\n",
    "    with open(edges_file_path, 'w') as file:\n",
    "        for edge in G.edges():\n",
    "            file.write(f\"{edge[0]} {edge[1]}\\n\")\n",
    "            \n",
    "def convert_edges_to_GML(filename):\n",
    "    # Create an empty graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Read the .edges file and add edges to the graph\n",
    "    with open(f'{filename}.edges', 'r') as file:\n",
    "        for line in file:\n",
    "            node1, node2 = line.strip().split()  # Assuming space-separated values\n",
    "            G.add_edge(int(node1), int(node2))\n",
    "\n",
    "    # Now save the graph to a GML file\n",
    "    gml_file_path = f'{filename}.gml'  # Replace with your desired output path\n",
    "    nx.write_gml(G, gml_file_path)\n",
    "\n",
    "\n",
    "\n",
    "names = [\n",
    "    'artist_edges',\n",
    "    'athletes_edges',\n",
    "    'company_edges',\n",
    "    'government_edges',\n",
    "    'new_sites_edges',\n",
    "    'politician_edges',\n",
    "    'public_figure_edges',\n",
    "    'tvshow_edges'\n",
    "]\n",
    "\n",
    "facebook2 = [\n",
    "    '1912',\n",
    "    '107',\n",
    "    '1684',\n",
    "    '3437',\n",
    "    '348',\n",
    "    '0',\n",
    "    '414',\n",
    "    '686',\n",
    "    '698',\n",
    "    '3980'    \n",
    "]\n",
    "\n",
    "for f in facebook2:\n",
    "    convert_edges_to_GML(f'CUDA_dataset/edges/facebook1/{f}')\n",
    "    \n",
    "# for n in names:\n",
    "#     nx.write_gml(read_graph(f'{filePath}/{n}.csv'), f'{filePath}/GMLs/{n}.gml')\n",
    "\n",
    "\n",
    "# for n in names:\n",
    "#     print(f'workin on {n}')\n",
    "#     G = nx.read_gml(f'CUDA_dataset/GMLs/{n}.gml')\n",
    "#     convert_graph(G, f'CUDA_dataset/edges/{n}.edges')    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on politician_edges\n",
      "Nodes = 5908\n",
      "Edges = 41729\n",
      "time consumed is: 104.99154925346375 seconds...AUC = 0.5012131242938754\n",
      "Network politician_edges completed...\n",
      "\n",
      "Working on public_figure_edges\n",
      "Nodes = 11565\n",
      "Edges = 67114\n",
      "time consumed is: 412.5483057498932 seconds...AUC = 0.49705744664813256\n",
      "Network public_figure_edges completed...\n",
      "\n",
      "Working on tvshow_edges\n",
      "Nodes = 3892\n",
      "Edges = 17262\n",
      "time consumed is: 41.84848618507385 seconds...AUC = 0.4964393636690764\n",
      "Network tvshow_edges completed...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filePath = \"CUDA_dataset/results\"\n",
    "_ = LocalSimilarity(names[5:], filePath, LP.CN, 'CN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on athletes_edges\n",
      "Nodes = 13866\n",
      "Edges = 86858\n",
      "time consumed is: 593.1397354602814 seconds...AUC = 0.505723467179865\n",
      "Network athletes_edges completed...\n",
      "\n",
      "Working on company_edges\n",
      "Nodes = 14113\n",
      "Edges = 52310\n",
      "time consumed is: 583.2835941314697 seconds...AUC = 0.4999852810103137\n",
      "Network company_edges completed...\n",
      "\n",
      "Working on government_edges\n",
      "Nodes = 7057\n",
      "Edges = 89455\n",
      "time consumed is: 143.78611135482788 seconds...AUC = 0.499950907817296\n",
      "Network government_edges completed...\n",
      "\n",
      "Working on new_sites_edges\n",
      "Nodes = 27917\n",
      "Edges = 206259\n",
      "time consumed is: 2574.571785211563 seconds...AUC = 0.5006127655130799\n",
      "Network new_sites_edges completed...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = LocalSimilarity(names[1:5], filePath, LP.CN, 'CN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = LocalSimilarity(facebook2, filePath, LP.RA, 'RA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = LocalSimilarity(facebook2, filePath, LP.PA, 'PA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = LocalSimilarity(facebook2, filePath, LP.JA, 'JA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = LocalSimilarity(facebook2, filePath, LP.SA, 'SA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = LocalSimilarity(facebook2, filePath, LP.HPI, 'HPI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1912,Nodes,747,Edges,30025,time,1.7127735614776611,AUC,0.49740720104060954\n",
      "\n",
      "107,Nodes,1034,Edges,26749,time,3.1168534755706787,AUC,0.507737187289643\n",
      "\n",
      "1684,Nodes,786,Edges,14024,time,1.6979007720947266,AUC,0.5183678044449984\n",
      "\n",
      "3437,Nodes,534,Edges,4813,time,0.7118735313415527,AUC,0.5053216572429332\n",
      "\n",
      "348,Nodes,224,Edges,3192,time,0.11908411979675293,AUC,0.502399359927682\n",
      "\n",
      "0,Nodes,333,Edges,2519,time,0.2634899616241455,AUC,0.5189306232045554\n",
      "\n",
      "414,Nodes,150,Edges,1693,time,0.05012869834899902,AUC,0.5071040917976074\n",
      "\n",
      "686,Nodes,168,Edges,1656,time,0.06427955627441406,AUC,0.480420477671766\n",
      "\n",
      "698,Nodes,61,Edges,270,time,0.007980585098266602,AUC,0.4711161176895222\n",
      "\n",
      "3980,Nodes,52,Edges,146,time,0.005849361419677734,AUC,0.4357863460475401\n"
     ]
    }
   ],
   "source": [
    "_ = LocalSimilarity(facebook2, filePath, LP.AA, 'AA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = LocalSimilarity(facebook2, filePath, LP.HDI, 'HDI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = LocalSimilarity(facebook2, filePath, LP.LLHN, 'LLHN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
